# ì•„í‚¤í…ì²˜ ê°€ì´ë“œ

DDOBAK RAG Source Collectorì˜ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì›ì¹™ê³¼ êµ¬ì¡°ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì…ë‹ˆë‹¤.

## ğŸ›ï¸ ì„¤ê³„ ì›ì¹™

### 1. í´ë¦° ì•„í‚¤í…ì²˜ (Clean Architecture)

í”„ë¡œì íŠ¸ëŠ” ë¡œë²„íŠ¸ ë§ˆí‹´ì˜ í´ë¦° ì•„í‚¤í…ì²˜ ì›ì¹™ì„ ë”°ë¦…ë‹ˆë‹¤:

- **ê´€ì‹¬ì‚¬ ë¶„ë¦¬**: ê° ëª¨ë“ˆì€ ë‹¨ì¼ ì±…ì„ì„ ê°€ì§‘ë‹ˆë‹¤
- **ì˜ì¡´ì„± ì—­ì „**: ê³ ìˆ˜ì¤€ ëª¨ë“ˆì´ ì €ìˆ˜ì¤€ ëª¨ë“ˆì— ì˜ì¡´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- **ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬**: í•„ìš”í•œ ì¸í„°í˜ì´ìŠ¤ë§Œ ë…¸ì¶œí•©ë‹ˆë‹¤

### 2. ëª¨ë“ˆí™” ì„¤ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Main (CLI)    â”‚    â”‚   Config        â”‚    â”‚   Utils         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         v                       v                       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Common Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ BaseCrawler   â”‚              â”‚ CrawlerRegistry             â”‚ â”‚
â”‚  â”‚ (Abstract)    â”‚              â”‚ (Plugin System)             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                   â”‚
         v                                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lawtalk        â”‚    â”‚  LawOpenAPI     â”‚    â”‚  EasyLaw        â”‚
â”‚  Crawler        â”‚    â”‚  Crawler        â”‚    â”‚  Crawler        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ ê³„ì¸µ êµ¬ì¡°

### 1. í”„ë ˆì  í…Œì´ì…˜ ê³„ì¸µ (Presentation Layer)

**ìœ„ì¹˜**: `main.py`

```python
# CLI ì¸í„°í˜ì´ìŠ¤
@click.command()
def main(site: str, simple_result: str, storage_type: str, only_new: str):
    # ì¸ì ê²€ì¦
    # í¬ë¡¤ëŸ¬ ìƒì„±
    # ì‹¤í–‰
```

**ì±…ì„**:
- CLI ì¸í„°í˜ì´ìŠ¤ ì œê³µ
- ì‚¬ìš©ì ì…ë ¥ ê²€ì¦
- í¬ë¡¤ë§ ì‹¤í–‰ ì¡°ìœ¨

### 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê³„ì¸µ (Business Logic Layer)

**ìœ„ì¹˜**: `common/`, ê° í¬ë¡¤ëŸ¬ ëª¨ë“ˆ

```python
# í¬ë¡¤ëŸ¬ ë² ì´ìŠ¤ í´ë˜ìŠ¤
class BaseCrawler(ABC):
    @abstractmethod
    def get_site_name(self) -> str: ...
    
    @abstractmethod
    def crawl(self) -> None: ...
    
    def run(self) -> None:
        # ê³µí†µ ì‹¤í–‰ íë¦„
```

**ì±…ì„**:
- í¬ë¡¤ë§ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
- ë°ì´í„° ì²˜ë¦¬ ë° ë³€í™˜
- ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…

### 3. ë°ì´í„° ì•¡ì„¸ìŠ¤ ê³„ì¸µ (Data Access Layer)

**ìœ„ì¹˜**: `utils/`

```python
# ë¡œì»¬ íŒŒì¼ ì €ì¥
def save_json_data_to_local(data, base_dir, file_path): ...

# S3 ì €ì¥
class S3Manager:
    def save_file(self, bucket, key, data): ...
```

**ì±…ì„**:
- ë°ì´í„° ì €ì¥ì†Œ ì¶”ìƒí™”
- íŒŒì¼ I/O ì²˜ë¦¬
- ì™¸ë¶€ ì„œë¹„ìŠ¤ í†µì‹ 

## ğŸ”Œ í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ

### Poetry Entry Points ê¸°ë°˜ êµ¬ì¡°

```toml
# pyproject.toml
[tool.poetry.plugins."ddobak.crawlers"]
lawtalk = "lawtalk.lawtalk_crawler:LawtalkCrawler"
law_open_api = "law_open_api.api_crawler:LawOpenAPICrawler"
```

### ë™ì  ë¡œë”© ë©”ì»¤ë‹ˆì¦˜

```python
# common/crawler_registry.py
def get_available_crawlers():
    crawlers = {}
    eps = entry_points(group='ddobak.crawlers')
    for ep in eps:
        crawlers[ep.name] = ep
    return crawlers

def create_crawler(site: str, options: dict):
    crawler_class = crawlers[site].load()
    return crawler_class(options)
```

**ì¥ì **:
- ìƒˆ í¬ë¡¤ëŸ¬ ì¶”ê°€ì‹œ ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš”
- ëŸ°íƒ€ì„ í¬ë¡¤ëŸ¬ ë°œê²¬
- ëª¨ë“ˆ ê°„ ëŠìŠ¨í•œ ê²°í•©

## ğŸ“Š ë°ì´í„° íë¦„

### 1. ì„¤ì • ë°ì´í„° íë¦„

```
[.env] â†’ [config.py] â†’ [LawtalkConfig] â†’ [Crawler]
  â†‘         â†‘              â†‘              â†‘
í™˜ê²½ë³€ìˆ˜   ì „ì—­ì„¤ì •      ì‚¬ì´íŠ¸ë³„ì„¤ì •    í¬ë¡¤ëŸ¬ì¸ìŠ¤í„´ìŠ¤
```

## ğŸ§© í™•ì¥ì„± ì„¤ê³„

### 1. ìƒˆë¡œìš´ í¬ë¡¤ëŸ¬ ì¶”ê°€

```python
# 1. í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ êµ¬í˜„
class NewSiteCrawler(BaseCrawler):
    def get_site_name(self) -> str:
        return "new_site"
    
    def crawl(self) -> None:
        # ì‚¬ì´íŠ¸ë³„ í¬ë¡¤ë§ ë¡œì§
        pass

# 2. pyproject.tomlì— ë“±ë¡
[tool.poetry.plugins."ddobak.crawlers"]
new_site = "new_site.crawler:NewSiteCrawler"

# 3. ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
poetry run start new_site
```

### 2. ìƒˆë¡œìš´ ì €ì¥ì†Œ íƒ€ì… ì¶”ê°€

```python
# utils/new_storage.py
class CloudStorageManager:
    def save_data(self, data, path): ...
    def load_data(self, path): ...

# ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ì—†ì´ ì‚¬ìš© ê°€ëŠ¥
```

## ğŸ”’ ë³´ì•ˆ ì„¤ê³„

### 1. í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì„¤ì •

```python
# ë¯¼ê°í•œ ì •ë³´ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬
LAWTALK_ID = os.getenv("LAWTALK_ID")
LAWTALK_PW = os.getenv("LAWTALK_PW")
AWS_ACCESS_KEY = os.getenv("AWS_ACCESS_KEY")
```

### 2. ì„¸ì…˜ ê´€ë¦¬

```python
# ë¡œê·¸ì¸ ì„¸ì…˜ ì•ˆì „ ê´€ë¦¬
class LawtalkCrawler:
    def _login(self):
        # ë¡œê·¸ì¸ í›„ ì„¸ì…˜ ì¿ í‚¤ ì €ì¥
        self.session_cookie = response.cookies['connect.sid']
    
    def cleanup(self):
        # í¬ë¡¤ë§ í›„ ì„¸ì…˜ ì •ë¦¬
        self.session = None
```

## ğŸ“ˆ ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­

### 1. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±

- **ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ëª¨ë‘ ë¡œë“œí•˜ì§€ ì•ŠìŒ
- **ë°°ì¹˜ ì²˜ë¦¬**: ë°ì´í„°ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
- **ì§€ì—° ë¡œë”©**: í•„ìš”í•  ë•Œë§Œ ë°ì´í„° ë¡œë“œ

### 2. ë„¤íŠ¸ì›Œí¬ ìµœì í™”

- **ìš”ì²­ ê°„ê²© ì¡°ì ˆ**: `REQUEST_INTERVAL` ì„¤ì •ìœ¼ë¡œ ì„œë²„ ë¶€í•˜ ë°©ì§€
- **ì„¸ì…˜ ì¬ì‚¬ìš©**: HTTP ì—°ê²° í’€ í™œìš©
- **ì¬ì‹œë„ ë¡œì§**: ì¼ì‹œì  ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì²˜ë¦¬

### 3. ì¦ë¶„ í¬ë¡¤ë§

```python
# ë§ˆì§€ë§‰ í¬ë¡¤ë§ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìƒˆ ë°ì´í„°ë§Œ ìˆ˜ì§‘
if only_new and last_crawl_time:
    if item_updated_at < last_crawl_time:
        break  # í¬ë¡¤ë§ ì¤‘ë‹¨
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±

### 1. ì˜ì¡´ì„± ì£¼ì…

```python
class BaseCrawler:
    def __init__(self, crawl_options: dict = None):
        self.crawl_options = crawl_options or {}
        # ì˜µì…˜ì„ í†µí•´ í…ŒìŠ¤íŠ¸ìš© ì„¤ì • ì£¼ì… ê°€ëŠ¥
```

### 2. ëª¨ì˜ ê°ì²´ ì§€ì›

```python
# í…ŒìŠ¤íŠ¸ì—ì„œ HTTP ìš”ì²­ì„ ëª¨ì˜í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„
class LawtalkCrawler:
    def __init__(self, session=None):
        self.session = session or requests.Session()
```

## ğŸ“ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§

### 1. êµ¬ì¡°í™”ëœ ë¡œê¹…

```python
# ê° í¬ë¡¤ëŸ¬ë³„ ë¡œê±°
logger = logging.getLogger(self.__class__.__name__)

# êµ¬ì¡°í™”ëœ ë¡œê·¸ ë©”ì‹œì§€
logger.info(f"Starting crawling for {site_name}")
logger.error(f"Crawling failed for {site_name}: {error}")
```

### 2. ì§„í–‰ ìƒí™© ì¶”ì 

```python
# í¬ë¡¤ë§ ì§„í–‰ ìƒí™© ë¡œê·¸
logger.info(f"Processed {count}/{total} items")
logger.info(f"Saved {files} files, {total_size} bytes")
```

ì´ ì•„í‚¤í…ì²˜ëŠ” í™•ì¥ì„±, ìœ ì§€ë³´ìˆ˜ì„±, í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±ì„ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ìƒˆë¡œìš´ ìš”êµ¬ì‚¬í•­ì— ìœ ì—°í•˜ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 